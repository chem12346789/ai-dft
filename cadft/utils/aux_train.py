"""
Generate list of keys for the dictionary that will store the model.
"""

from itertools import product
from pathlib import Path
import datetime

import torch

from cadft.utils.nao import NAO
from cadft.utils.model.fc_net import FCNet as Model

# from cadft.utils.model.transformer import Transformer as Model


def gen_keys_l(atom_list):
    """
    input:
        atom_list: list of atom names
    output:
        keys: 1st and 2nd words are atom names, 3rd is if diagonal (H-H-O or H-H-D)
    """
    keys_l = []

    for i_atom, j_atom in product(atom_list, atom_list):
        if i_atom != j_atom:
            atom_name = f"{i_atom}-{j_atom}"
            keys_l.append(atom_name)
        else:
            atom_name = f"{i_atom}-{i_atom}-D"
            keys_l.append(atom_name)
            atom_name = f"{i_atom}-{i_atom}-O"
            keys_l.append(atom_name)
    return keys_l


class ModelDict:
    """
    Model_Dict
    """

    def __init__(self, keys_l, hidden_size, args, device):
        """
        input:
            keys: keys of dictionary, generated by gen_keys_l
        output:
            model_dict: dictionary of models
        """
        self.keys_l = keys_l
        self.hidden_size = hidden_size
        self.args = args
        self.device = device

        self.model_dict = {}
        self.model_dict["size"] = {}
        self.dir_checkpoint = Path(
            f"checkpoints/checkpoint-ccdft-{datetime.datetime.today():%Y-%m-%d-%H-%M-%S}-{args.hidden_size}/"
        ).resolve()
        self.dir_checkpoint.mkdir(parents=True, exist_ok=True)

        for key in keys_l:
            self.model_dict[key + "1"] = Model(75, hidden_size, 75, args).to(device)
            self.model_dict[key + "1"].double()
            self.model_dict["size"][key] = 75

            self.model_dict[key + "2"] = Model(75, hidden_size, 75, args).to(device)
            self.model_dict[key + "2"].double()

    def load_model(self, load):
        """
        Load the model from the checkpoint.
        """
        if load != "":
            dir_load = Path(f"checkpoints/checkpoint-ccdft-{load}-{self.hidden_size}/")
            for key in self.keys_l:
                for i_str in ["1", "2"]:
                    key_i_str = key + i_str
                    list_of_path = list(dir_load.glob(f"{key}-{i_str}*.pth"))
                    if len(list_of_path) == 0:
                        print(
                            f"No model found for {key_i_str}, use random initialization."
                        )
                        continue
                    load_path = max(list_of_path, key=lambda p: p.stat().st_ctime)
                    state_dict = torch.load(load_path, map_location=self.device)
                    self.model_dict[key_i_str].load_state_dict(state_dict)
                    print(f"Model loaded from {load_path}")

    def save_model(self, epoch):
        """
        Save the model to the checkpoint.
        """
        for key in self.keys_l:
            for i_str in ["1", "2"]:
                state_dict = self.model_dict[key + i_str].state_dict()
                torch.save(
                    state_dict,
                    self.dir_checkpoint / f"{key}-{i_str}-{epoch}.pth",
                )
